<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>ctownsen357@github.io</title>
    <link>http://ctownsen357.github.io/tags/r/index.xml</link>
    <description>Recent content on ctownsen357@github.io</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-gb</language>
    <atom:link href="http://ctownsen357.github.io/tags/r/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Compiled R</title>
      <link>http://ctownsen357.github.io/posts/compiled-r/</link>
      <pubDate>Sun, 08 Jan 2017 17:08:34 -0500</pubDate>
      
      <guid>http://ctownsen357.github.io/posts/compiled-r/</guid>
      <description>

&lt;p&gt;While investigating ways to make some R code more performant I came across the compiler package.  This package allows one to compile functions and/or entire files into compiled bytecode.  Alternatively one may also enable just-in-time compilation.  In my use case with Rserve the JIT compilation options actually made performance worse because each session was recompiling everything rather than sharing compiled source.  In my case the way forward was to compile the files into bytecode so they were precompiled manually and available as bytecode files.&lt;/p&gt;

&lt;h2 id=&#34;just-in-time-compile&#34;&gt;Just-in-time Compile&lt;/h2&gt;
&lt;div class=&#34;highlight&#34; style=&#34;background: #272822&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;library&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;(&lt;/span&gt;compiler&lt;span style=&#34;color: #f8f8f2&#34;&gt;)&lt;/span&gt;
enableJIT&lt;span style=&#34;color: #f8f8f2&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #ae81ff&#34;&gt;3&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The options for JIT are 0 through 3, inicating no JIT through the max level where everything possible is compiled before first use.&lt;/p&gt;

&lt;h2 id=&#34;compiling-functions&#34;&gt;Compiling functions&lt;/h2&gt;
&lt;div class=&#34;highlight&#34; style=&#34;background: #272822&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;library&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;(&lt;/span&gt;compiler&lt;span style=&#34;color: #f8f8f2&#34;&gt;)&lt;/span&gt;
myfoo &lt;span style=&#34;color: #f92672&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span style=&#34;color: #66d9ef&#34;&gt;function&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;(){&lt;/span&gt;
    &lt;span style=&#34;color: #66d9ef&#34;&gt;seq&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #ae81ff&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;:&lt;/span&gt;&lt;span style=&#34;color: #ae81ff&#34;&gt;5&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;)&lt;/span&gt;
&lt;span style=&#34;color: #f8f8f2&#34;&gt;}&lt;/span&gt;

compiledfoo &lt;span style=&#34;color: #f92672&#34;&gt;&amp;lt;-&lt;/span&gt; cmpfun&lt;span style=&#34;color: #f8f8f2&#34;&gt;(&lt;/span&gt;myfoo&lt;span style=&#34;color: #f8f8f2&#34;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;That example is not going to yield any performance benefit because seq is already compiled but it demonstrates HOW to compile a function.  My experience was that it is about 2-3 times faster and is most helpful for a function that gets called multiple times.&lt;/p&gt;

&lt;h2 id=&#34;compiling-an-entire-r-file&#34;&gt;Compiling an entire R file&lt;/h2&gt;
&lt;div class=&#34;highlight&#34; style=&#34;background: #272822&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;library&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;(&lt;/span&gt;compiler&lt;span style=&#34;color: #f8f8f2&#34;&gt;)&lt;/span&gt;
cmpfile&lt;span style=&#34;color: #f8f8f2&#34;&gt;(&lt;/span&gt;infile&lt;span style=&#34;color: #f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#39;&amp;lt;path_to_file&amp;gt;.R&amp;#39;&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;This will compile the entire R file down to bytecode in the same location with an extension of .Rc  This compiled file may then be sourced in other R files and the performance benefits I saw were highly dependent on the types of routines being called.&lt;/p&gt;

&lt;h2 id=&#34;sourcing-your-newly-compiled-r-file&#34;&gt;Sourcing your newly compiled R file&lt;/h2&gt;
&lt;div class=&#34;highlight&#34; style=&#34;background: #272822&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;library&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;(&lt;/span&gt;compiler&lt;span style=&#34;color: #f8f8f2&#34;&gt;)&lt;/span&gt;

loadcmp&lt;span style=&#34;color: #f8f8f2&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#39;&amp;lt;path/to/compiled/file&amp;gt;.Rc&amp;#39;&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;)&lt;/span&gt;
&lt;span style=&#34;color: #75715e&#34;&gt;# call all of your functions as you normally would&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>R and ff, and many columns! Oh my!</title>
      <link>http://ctownsen357.github.io/posts/r-ff-many-columns/</link>
      <pubDate>Fri, 02 Dec 2016 10:28:40 -0500</pubDate>
      
      <guid>http://ctownsen357.github.io/posts/r-ff-many-columns/</guid>
      <description>

&lt;p&gt;Recently, I was experimenting with a data set in R that ended up being more challenging than I first expected.  It really wasn&amp;rsquo;t that large as far as size on disk or memory(single instance) was concerned but it had over 3,000 columns.&lt;/p&gt;

&lt;p&gt;At first I didn&amp;rsquo;t think it was that big of a deal and it wouldn&amp;rsquo;t be if one only needed a single instance of the ~ 750MB file in memory.  What if you have a web application that instantiates that data set on a server for each user and you have many concurrent users? All of a sudden that 750MB and any operations on that data can quickly exhaust available RAM.&lt;/p&gt;

&lt;p&gt;I looked at the bigmemory package because it looked promising and contained some tech under the hood that I&amp;rsquo;ve used: memory mapped files and shared memory via the C++ boost libraries.  That combination allows a single instance of a matrix to be accessed by multiple processes.  The problem with that ended up being that the dat set was not a matrix of uniform type but mixed types.  Enter the ff and ffbase packages!&lt;/p&gt;

&lt;p&gt;The ff package provides data structures that are stored on disk but behave (almost) as if they were in RAM by transparently mapping only a section (pagesize) in main memory - the effective virtual memory consumption per ff object.&lt;/p&gt;

&lt;p&gt;I loaded the original data frame and tried to cast it to an ffdf (ff data frame):&lt;/p&gt;
&lt;div class=&#34;highlight&#34; style=&#34;background: #272822&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&#34;color: #f92672&#34;&gt;require&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;(&lt;/span&gt;ffbase&lt;span style=&#34;color: #f8f8f2&#34;&gt;)&lt;/span&gt;
&lt;span style=&#34;color: #66d9ef&#34;&gt;load&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#39;./35509-0001-Data.rda&amp;#39;&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;)&lt;/span&gt;
testffdf &lt;span style=&#34;color: #f92672&#34;&gt;&amp;lt;-&lt;/span&gt; as.ffdf&lt;span style=&#34;color: #f8f8f2&#34;&gt;(&lt;/span&gt;da35509.0001&lt;span style=&#34;color: #f8f8f2&#34;&gt;,&lt;/span&gt; vmode &lt;span style=&#34;color: #f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color: #66d9ef&#34;&gt;NULL&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;)&lt;/span&gt;
save.ffdf&lt;span style=&#34;color: #f8f8f2&#34;&gt;(&lt;/span&gt;testffdf&lt;span style=&#34;color: #f8f8f2&#34;&gt;,&lt;/span&gt; dir&lt;span style=&#34;color: #f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #e6db74&#34;&gt;&amp;quot;./testdf&amp;quot;&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;,&lt;/span&gt; relative&lt;span style=&#34;color: #f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #66d9ef&#34;&gt;TRUE&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;It failed silently.  I looked in the &lt;code&gt;./testdf&lt;/code&gt; and nothing.  Ugh, what appeared so promising now looked bleak!&lt;/p&gt;

&lt;p&gt;After some additional tinkering, I received an actual error.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Error en  ff(initdata = initdata, length = length, levels = levels, ordered = ordered,  : 
   write error

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Not very descriptive but it was something to go on.  After some searching &lt;a href=&#34;http://stackoverflow.com/questions/14025202/ff-package-write-error&#34;&gt;I came across this thread on stackoverflow.&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The answers were not entirely helpful but they did discuss that each column in an ff data frame are stored in distinct files.  Bingo! I&amp;rsquo;ve encountered bumping into exceeding the max number of files open on a system before and it is a very simple fix.  Keep in mind the file limits are in place to prevent resource exhaustion on the system.  Those limits are set VERY conservatively though.  Increasing the limits is as simple as the following:&lt;/p&gt;

&lt;h3 id=&#34;linux&#34;&gt;Linux:&lt;/h3&gt;

&lt;p&gt;Add the following to your &lt;code&gt;/etc/security/limits.conf&lt;/code&gt; file.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;youruserid  hard  nofile 100000 # you may enter whatever number you wish here
youruserid  soft  nofile  10000 # whatever you want the default to be for each shell or process you have running
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;os-x&#34;&gt;OS X:&lt;/h3&gt;

&lt;p&gt;Add or edit the following in your &lt;code&gt;/etc/sysctl.con&lt;/code&gt; file.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;kern.maxfilesperproc=166384
kern.maxfiles=8192
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You&amp;rsquo;ll need to log out and log back in for the change to take effect.  After that change, one may use the ff data frame with up to the number of columns you specified in your &lt;code&gt;limits.conf&lt;/code&gt; or &lt;code&gt;sysctl.con&lt;/code&gt; file.&lt;/p&gt;

&lt;p&gt;Now I&amp;rsquo;m able to load  what was 750MB per data frame instance as a ffdf and only consume ~ 11MB of RAM per instance.  Many parallel instances of the R routines using this data may be run without exhausting available RAM.  Keep in mind that you&amp;rsquo;ll want to tweak your max open file settings to account for expected concurrent use.&lt;/p&gt;

&lt;p&gt;You can test this by opening up a new R session, changing directories to where you were working previously and loading the ffdf from disk:&lt;/p&gt;
&lt;div class=&#34;highlight&#34; style=&#34;background: #272822&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;required&lt;span style=&#34;color: #f8f8f2&#34;&gt;(&lt;/span&gt;ffbase&lt;span style=&#34;color: #f8f8f2&#34;&gt;)&lt;/span&gt;
load.ffdf&lt;span style=&#34;color: #f8f8f2&#34;&gt;(&lt;/span&gt;&lt;span style=&#34;color: #e6db74&#34;&gt;&amp;#39;./testdf&amp;#39;&lt;/span&gt;&lt;span style=&#34;color: #f8f8f2&#34;&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Your should now have an instance of the original testffdf object.&lt;/p&gt;

&lt;p&gt;A helpful presentation on the ff and ffbase packages is &lt;a href=&#34;http://ff.r-forge.r-project.org/ff&amp;amp;bit_UseR!2009.pdf&#34;&gt;available here&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>