<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Docker on ctownsen357@github.io</title>
    <link>http://ctownsen357.github.io/tags/docker/index.xml</link>
    <description>Recent content in Docker on ctownsen357@github.io</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-gb</language>
    <atom:link href="http://ctownsen357.github.io/tags/docker/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>GlusterFS &amp; Docker</title>
      <link>http://ctownsen357.github.io/posts/glusterfs-docker/</link>
      <pubDate>Tue, 08 Nov 2016 16:28:48 -0500</pubDate>
      
      <guid>http://ctownsen357.github.io/posts/glusterfs-docker/</guid>
      <description>

&lt;p&gt;I&amp;rsquo;ve recently started exploring &lt;a href=&#34;https://www.gluster.org/&#34;&gt;GlusterFS&lt;/a&gt; in Docker containers to use as persistent storage for the Dockerized services and applications I&amp;rsquo;ve been working on.  If this is performant enough then for my purposes it will close the gap for me to really treat the data center as one giant computer.  Getting started was pretty straight forward.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; This is a quick example.  Make sure you read up on security, changing the default password, and review the original Dockerfile.  I&amp;rsquo;ll be experimenting with running this out on AWS soon and should be able to further tighten up my example.&lt;/p&gt;

&lt;h3 id=&#34;get-the-latest-gluster-container&#34;&gt;Get the latest Gluster container:&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/gluster/gluster-containers&#34;&gt;Get the latest container:&lt;/a&gt;&lt;/p&gt;
docker pull gluster/gluster-centos

&lt;h3 id=&#34;make-the-persistent-data-folders-on-each-host&#34;&gt;Make the persistent data folders on each host:&lt;/h3&gt;
sudo mkdir -p /gluster/logs &amp;&amp; sudo mkdir /gluster/data &amp;&amp; sudo mkdir /gluster/config &amp;&amp; /gluster/mnt

&lt;h3 id=&#34;start-a-glusterfs-container-on-each-host&#34;&gt;Start a GlusterFS container on each host:&lt;/h3&gt;
docker run -d \
   --name gluster \
   --privileged \
   --net=host \
   -v /gluster/data:/gluster \
   -v /gluster/logs:/var/log/glusterfs \
   -v /gluster/config:/var/lib/glusterd \
   -v /gluster/mnt:/gluster/mnt \
   gluster/gluster-centos

&lt;h3 id=&#34;probe-the-hosts-in-the-cluster&#34;&gt;Probe the hosts in the cluster:&lt;/h3&gt;

&lt;p&gt;For each container on each host you&amp;rsquo;ll want to execute this to get them aware of the other peers.  If running out on AWS these steps could be orchestrated through the init system on the hosts so you don&amp;rsquo;t have to log into each machine.&lt;/p&gt;
gluster peer probe 1.1.1.1

&lt;h3 id=&#34;now-create-your-volume-and-start-it&#34;&gt;Now create your volume and start it:&lt;/h3&gt;
gluster volume create media replica 3 transport tcp 172.30.0.185:/gluster/data  172.30.0.186:/gluster/data 172.30.0.30:/
gluster volume start media

&lt;p&gt;In this example I&amp;rsquo;m replicating across each of three servers but depending on your needs you could: distributed striped, distributed, replicated, distributed striped replicated, &amp;hellip; know what and why.&lt;/p&gt;

&lt;h3 id=&#34;mount-the-volume&#34;&gt;Mount the volume&lt;/h3&gt;

&lt;p&gt;The docs made a big deal out of mounting the volume.  I suspect if you were doing anything other than replicating that would become very important.&lt;/p&gt;

&lt;p&gt;You&amp;rsquo;ll want to do this on each host, using its internal ip:&lt;/p&gt;
mount -t glusterfs 172.30.0.186:/media /gluster/mnt

&lt;p&gt;From one of the hosts testing with a write statement to the volume:&lt;/p&gt;
echo &#34;testing, 1,2,3...&#34; &gt;&gt; /gluster/mnt/test.txt

&lt;p&gt;And from another host you should be able to read/write to the same document.  One could then launch containers on any host with a mount to /gluster/mnt to store data.  Then it would have access to the data no matter which node it was launched on.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>CoreOS Mount NTFS Share</title>
      <link>http://ctownsen357.github.io/posts/coreos-mount-ntfs-share/</link>
      <pubDate>Tue, 01 Nov 2016 14:12:12 -0400</pubDate>
      
      <guid>http://ctownsen357.github.io/posts/coreos-mount-ntfs-share/</guid>
      <description>&lt;p&gt;I had the need to mount an NTFS share for an application that was connecting to a SQL Server database and required that a share be mapped.  While testing from my CentOS 7 desktop, creating the share was trivial.  Not so much once I transitioned over to a CoreOS machine where I was to deploy for user testing.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; I map /opt/bin from the host to a folder in the container.  I store custom binaries and scripts in /opt/bin on CoreOS as it is in the path and persists even after CoreOS updates to the latest version.  I&amp;rsquo;ve also changed the example from a Fedora container to CentOS as CentOS already has items installed that the example I link to installed in addition to the dev tools and libraries.&lt;/p&gt;

&lt;p&gt;This is how I got around that problem:&lt;/p&gt;
docker run -t -i -v /opt/bin:/host_tmp centos /bin/bash
yum groupinstall -y &#34;Development Tools&#34; &#34;Development Libraries&#34;

curl https://download.samba.org/pub/linux-cifs/cifs-utils/cifs-utils-6.3.tar.bz2 | bunzip2 -c - | tar -xvf -
cd cifs-utils-6.3/
./configure &amp;&amp; make
cp mount.cifs /host_tmp/
exit

sudo mkdir /media/foo
sudo mount.cifs &#34;//1.1.1.1/ntfs_share&#34; -o username=winuser,domain=mydomain.com,rw,dir_mode=0775,noperm /media/foo/ 

&lt;p&gt;Originally &lt;a href=&#34;https://gist.github.com/pantelis/540a19262cacc841fb0a&#34;&gt;found here&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Monitor Docker Events with Awk</title>
      <link>http://ctownsen357.github.io/posts/awk-mon/</link>
      <pubDate>Tue, 01 Nov 2016 09:38:04 -0400</pubDate>
      
      <guid>http://ctownsen357.github.io/posts/awk-mon/</guid>
      <description>&lt;p&gt;I recently wrote a Docker event monitor in Go as an excercise to demonstrate some proficiency in Go and Docker.  Before getting started I was thinking about how it could be done with piping, bash, and awk.  It was actually really easy to do.  Some of the excercise requirements were:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;The service should monitor the Docker API for restart events&lt;/li&gt;
&lt;li&gt;The service should run an arbitrary command in response to that event.&lt;/li&gt;
&lt;li&gt;The arbitrary command should be supplied via a config file.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The pipe, bash, awk solution:&lt;/p&gt;
echo &#39; pwd&#39; &gt; cmd.txt &amp;&amp; docker events | awk &#39;/container restart/{system(&#34;echo docker exec &#34; $4 &#34; $(cat cmd.txt) | bash -&#34;)}&#39;

&lt;p&gt;This pipes the pwd command into a file and then pipes the stream from docker events into awk which is searching for the restart event.  When the restart event is encountered it executes the arbitrary command from the text file against the restarted container.  The command in the text file could be replaced with any desired command.&lt;/p&gt;

&lt;p&gt;There were other requirements that made it interesting to think through in Go.  I&amp;rsquo;ll be posting the entire excercise and my code soon.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>